# Research Synthesis: Agile Coach Agent

## Research Methodology

**CRITICAL: Research Campaign Status - INCOMPLETE DUE TO TOOL CONSTRAINTS**

- Date of research: 2026-02-08
- Total searches executed: **0** (WebSearch tool unavailable)
- Total sources evaluated: **0** (WebFetch tool unavailable)
- Sources included (CRAAP score 15+): **0**
- Sources excluded (CRAAP score < 15): **0**
- Target agent archetype: **Coach/Orchestrator**
- Research areas covered: **0 of 6** (all areas are GAPS)
- Identified gaps: **6 complete research areas** (28 sub-questions)

### Tool Availability Constraint

This research campaign could not be completed because both required web research tools were unavailable:
- **WebSearch**: Permission auto-denied (prompts unavailable)
- **WebFetch**: Permission auto-denied (prompts unavailable)

Per the Deep Research Agent protocol:
> "You do not guess, improvise, or fill gaps with plausible-sounding content. Every finding you report traces to a specific source. When you cannot find information, you say so explicitly and document the gap."

Therefore, this document provides:
1. The complete planned research framework
2. All queries that should be executed when tools become available
3. Documentation of gaps with planned query lists
4. NO fabricated findings without source attribution

### Recommended Action

To complete this research:
1. **Enable web research tools** (WebSearch and WebFetch)
2. **Re-run this research prompt** with tools available
3. **Execute the planned queries** documented in each research area below
4. **Follow the full Deep Research Agent protocol** (Phases 1-6)

---

## Area 1: Modern Agile Practices (2025-2026) - GAP

### Sub-Questions (All GAPS)
1. What are current best practices for agile software development?
2. How have Scrum, Kanban, and hybrid approaches evolved?
3. What are the latest patterns for agile in remote/distributed teams?
4. How do modern agile practices integrate with AI-assisted development?
5. What are current patterns for measuring agile team effectiveness?

### Planned Queries (Not Executed - Tool Unavailable)

**Query Set 1A: Current Practices**
- `"agile software development best practices 2026"`
- `"agile methodology evolution 2025 2026"`
- `"modern agile practices production experience"`
- `"agile development trends emerging 2026"`

**Query Set 1B: Framework Evolution**
- `"Scrum 2026 changes updates"`
- `"Kanban best practices 2026"`
- `"Scrum vs Kanban vs Scrumban comparison 2025"`
- `"hybrid agile approaches 2026"`
- `"site:scrumguides.org scrum guide 2020"`

**Query Set 1C: Remote/Distributed Patterns**
- `"agile remote distributed teams patterns 2026"`
- `"remote agile best practices 2025"`
- `"distributed agile team collaboration tools"`
- `"asynchronous agile practices"`

**Query Set 1D: AI Integration**
- `"AI-assisted agile development 2026"`
- `"AI coding assistants agile practices"`
- `"agile with AI developers 2025"`
- `"AI impact on agile teams production"`

**Query Set 1E: Effectiveness Measurement**
- `"measuring agile team effectiveness 2026"`
- `"agile team performance metrics"`
- `"agile maturity assessment models"`
- `"agile metrics anti-patterns avoid"`

### Authoritative Sources to Target
- Official Scrum Guide (scrumguides.org)
- Agile Alliance (agilealliance.org)
- Martin Fowler's agile content (martinfowler.com/agile.html)
- Scrum.org resources
- Atlassian Agile guides
- InfoQ agile content
- Conference talks: Agile Alliance conferences, QCon

### Key Findings
**GAP**: No findings. All 5 sub-questions require web research with the queries listed above.

### Sources
**GAP**: No sources evaluated. Recommend starting with official Scrum Guide and Agile Alliance resources.

---

## Area 2: Sprint & Iteration Management - GAP

### Sub-Questions (All GAPS)
1. What are current best practices for sprint planning and estimation?
2. How do story points, t-shirt sizing, and no-estimates approaches compare?
3. What are the latest patterns for sprint retrospectives that drive improvement?
4. How should teams handle sprint scope changes and interruptions?
5. What are current patterns for definition of done and acceptance criteria?

### Planned Queries (Not Executed - Tool Unavailable)

**Query Set 2A: Sprint Planning**
- `"sprint planning best practices 2026"`
- `"agile estimation techniques comparison 2025"`
- `"sprint planning anti-patterns avoid"`
- `"effective sprint planning remote teams"`

**Query Set 2B: Estimation Approaches**
- `"story points vs no estimates 2026"`
- `"t-shirt sizing estimation agile"`
- `"estimation techniques comparison agile"`
- `"no estimates movement 2025 criticism"`
- `"story points benefits drawbacks"`
- `"agile estimation real-world experience"`

**Query Set 2C: Retrospectives**
- `"sprint retrospectives drive improvement 2025"`
- `"effective retrospective formats"`
- `"retrospective fatigue solutions"`
- `"data-driven retrospectives"`
- `"retrospective anti-patterns avoid"`

**Query Set 2D: Scope Management**
- `"sprint scope changes interruptions handling"`
- `"agile scope creep management"`
- `"sprint commitment vs forecast"`
- `"unplanned work agile teams"`

**Query Set 2E: Definition of Done**
- `"definition of done best practices 2026"`
- `"acceptance criteria patterns agile"`
- `"DoD vs acceptance criteria"`
- `"definition of done examples production"`

### Authoritative Sources to Target
- Scrum.org blog and resources
- Mountain Goat Software (Mike Cohn)
- Roman Pichler's blog
- Atlassian sprint planning guides
- Henrik Kniberg's content
- Allen Holub's no estimates perspective

### Key Findings
**GAP**: No findings. All 5 sub-questions require web research with the queries listed above.

### Sources
**GAP**: No sources evaluated. Recommend starting with Scrum.org and Mountain Goat Software.

---

## Area 3: Team Dynamics & Coaching - GAP

### Sub-Questions (All GAPS)
1. What are current best practices for coaching agile teams?
2. How should coaches identify and address team dysfunction (Lencioni model)?
3. What are the latest patterns for building psychological safety in teams?
4. How do servant leadership principles apply in modern agile coaching?
5. What are current patterns for coaching teams through transformation?

### Planned Queries (Not Executed - Tool Unavailable)

**Query Set 3A: Coaching Best Practices**
- `"agile coaching best practices 2026"`
- `"professional agile coaching 2025"`
- `"agile coach responsibilities patterns"`
- `"coaching vs mentoring agile teams"`

**Query Set 3B: Team Dysfunction**
- `"Lencioni five dysfunctions agile teams"`
- `"identifying team dysfunction patterns"`
- `"addressing team conflict agile coaching"`
- `"team dysfunction diagnostic models"`

**Query Set 3C: Psychological Safety**
- `"psychological safety agile teams 2026"`
- `"building trust agile teams"`
- `"Google Project Aristotle findings"`
- `"Amy Edmondson psychological safety"`
- `"psychological safety patterns production"`

**Query Set 3D: Servant Leadership**
- `"servant leadership agile coaching 2025"`
- `"servant leadership principles modern agile"`
- `"servant leadership vs traditional management"`
- `"servant leadership real-world experience"`

**Query Set 3E: Transformation Coaching**
- `"coaching agile transformation 2026"`
- `"agile transformation patterns success"`
- `"agile transformation anti-patterns failure"`
- `"change management agile adoption"`

### Authoritative Sources to Target
- Lyssa Adkins coaching content
- Amy Edmondson psychological safety research
- Patrick Lencioni's five dysfunctions
- Scrum Alliance coaching resources
- Industrial Logic agile coaching
- Agile Coaching Institute

### Key Findings
**GAP**: No findings. All 5 sub-questions require web research with the queries listed above.

### Sources
**GAP**: No sources evaluated. Recommend starting with Lyssa Adkins and Amy Edmondson's research.

---

## Area 4: Scaled Agile - GAP

### Sub-Questions (All GAPS)
1. What are current best practices for scaling agile (SAFe, LeSS, Nexus)?
2. How should organizations coordinate across multiple agile teams?
3. What are the latest patterns for portfolio-level agile planning?
4. How do dependencies between teams get managed in scaled agile?
5. What are current patterns for organizational agile transformation?

### Planned Queries (Not Executed - Tool Unavailable)

**Query Set 4A: Scaling Frameworks**
- `"SAFe vs LeSS vs Nexus comparison 2026"`
- `"scaled agile framework best practices 2025"`
- `"SAFe criticism drawbacks limitations"`
- `"LeSS framework benefits advantages"`
- `"Nexus scaling framework patterns"`
- `"scaling agile real-world experience"`

**Query Set 4B: Multi-Team Coordination**
- `"coordinating multiple agile teams 2026"`
- `"Scrum of Scrums patterns 2025"`
- `"agile team coordination anti-patterns"`
- `"cross-team collaboration patterns"`

**Query Set 4C: Portfolio Planning**
- `"portfolio-level agile planning 2026"`
- `"agile portfolio management patterns"`
- `"OKRs and agile planning integration"`
- `"strategic planning agile organizations"`

**Query Set 4D: Dependency Management**
- `"managing dependencies scaled agile"`
- `"inter-team dependencies patterns"`
- `"dependency mapping agile teams"`
- `"dependency hell solutions agile"`

**Query Set 4E: Organizational Transformation**
- `"organizational agile transformation 2026"`
- `"enterprise agile adoption patterns"`
- `"agile transformation failure lessons"`
- `"scaling agile culture change"`

### Authoritative Sources to Target
- Scaled Agile (SAFe official site)
- LeSS official documentation
- Scrum.org Nexus guide
- Spotify engineering blog (squad model)
- Craig Larman's LeSS content
- Dean Leffingwell's SAFe content

### Key Findings
**GAP**: No findings. All 5 sub-questions require web research with the queries listed above.

### Sources
**GAP**: No sources evaluated. Recommend starting with official framework documentation and comparing approaches.

---

## Area 5: Metrics & Continuous Improvement - GAP

### Sub-Questions (All GAPS)
1. What are the DORA and SPACE metrics and how should they be applied?
2. How should teams use flow metrics (cycle time, throughput, WIP)?
3. What are the latest patterns for data-driven agile coaching?
4. How do teams implement effective continuous improvement loops?
5. What are current patterns for OKR integration with agile planning?

### Planned Queries (Not Executed - Tool Unavailable)

**Query Set 5A: DORA and SPACE Metrics**
- `"DORA metrics 2026 best practices"`
- `"SPACE framework developer productivity"`
- `"DORA metrics implementation guide"`
- `"DORA metrics misuse anti-patterns"`
- `"site:dora.dev metrics guide"`

**Query Set 5B: Flow Metrics**
- `"flow metrics cycle time throughput WIP"`
- `"kanban flow metrics agile teams"`
- `"cumulative flow diagram patterns"`
- `"flow metrics anti-patterns avoid"`

**Query Set 5C: Data-Driven Coaching**
- `"data-driven agile coaching 2026"`
- `"metrics for agile coaches"`
- `"evidence-based agile coaching"`
- `"actionable metrics agile teams"`

**Query Set 5D: Continuous Improvement**
- `"continuous improvement loops agile"`
- `"kaizen agile teams"`
- `"improvement kata software teams"`
- `"retrospective actions tracking"`

**Query Set 5E: OKR Integration**
- `"OKRs agile planning integration 2026"`
- `"OKRs vs sprint goals"`
- `"OKR frameworks agile teams"`
- `"OKR anti-patterns agile"`

### Authoritative Sources to Target
- DORA official site (dora.dev)
- Google's SPACE framework paper
- Accelerate book findings (Forsgren, Humble, Kim)
- Kanban University resources
- Atlassian agile metrics guides
- John Doerr's OKR content

### Key Findings
**GAP**: No findings. All 5 sub-questions require web research with the queries listed above.

### Sources
**GAP**: No sources evaluated. Recommend starting with DORA official documentation and Accelerate book.

---

## Area 6: AI-Augmented Agile - GAP

### Sub-Questions (All GAPS)
1. How is AI changing agile practices in 2025-2026?
2. What are current patterns for AI-assisted sprint planning and estimation?
3. How should agile processes adapt for AI-first development teams?
4. What are the latest patterns for AI-generated retrospective insights?
5. How do AI coding assistants change team velocity and capacity planning?

### Planned Queries (Not Executed - Tool Unavailable)

**Query Set 6A: AI Impact on Agile**
- `"AI impact on agile practices 2026"`
- `"artificial intelligence agile development 2025"`
- `"AI changing software development agile"`
- `"AI-augmented agile teams production"`

**Query Set 6B: AI-Assisted Planning**
- `"AI-assisted sprint planning 2026"`
- `"AI estimation tools agile"`
- `"machine learning sprint forecasting"`
- `"AI sprint planning benefits drawbacks"`

**Query Set 6C: AI-First Development**
- `"AI-first development agile processes 2026"`
- `"GitHub Copilot agile team impact"`
- `"AI pair programming agile workflows"`
- `"adapting agile for AI developers"`

**Query Set 6D: AI Retrospective Tools**
- `"AI-generated retrospective insights"`
- `"AI tools for agile retrospectives 2026"`
- `"sentiment analysis agile teams"`
- `"AI coaching recommendations"`

**Query Set 6E: Velocity and Capacity**
- `"AI coding assistants team velocity impact"`
- `"GitHub Copilot productivity metrics"`
- `"AI tools capacity planning agile"`
- `"measuring AI impact on velocity"`

### Authoritative Sources to Target
- GitHub Engineering blog (Copilot impact)
- Microsoft Research (AI developer tools)
- ThoughtWorks Technology Radar
- Martin Fowler on AI and development
- InfoQ AI/ML content
- Recent conference talks (QCon, Agile 2025)

### Key Findings
**GAP**: No findings. All 5 sub-questions require web research with the queries listed above. This is the most rapidly evolving area and requires current (2025-2026) sources.

### Sources
**GAP**: No sources evaluated. Recommend starting with GitHub and Microsoft research on AI coding assistants.

---

## Synthesis

Due to the complete absence of research findings, the synthesis sections below cannot be populated. Each section documents what SHOULD be included when research is completed.

### 1. Core Knowledge Base

**GAP**: This section should contain definitive statements about:
- Core agile principles and values
- Scrum roles, events, and artifacts
- Kanban principles and practices
- Flow-based metrics definitions
- DORA metrics (deployment frequency, lead time, MTTR, change fail rate)
- SPACE metrics (Satisfaction, Performance, Activity, Communication, Efficiency)
- Psychological safety principles
- Servant leadership concepts
- Scaled agile framework comparisons
- AI impact on agile practices

**Required Research**: Execute all queries in Areas 1-6 above to populate this knowledge base.

**Example Format** (when research is complete):
- **Scrum Sprint**: Time-boxed iteration of 1-4 weeks (typically 2 weeks) where a team creates a potentially shippable increment: [source URL] [Confidence: HIGH]

### 2. Decision Frameworks

**GAP**: This section should contain conditional guidance such as:
- When [team symptom] appears, diagnose as [root cause] and recommend [practice] because [reason]
- When to choose Scrum vs Kanban vs hybrid
- When to scale agile (and which framework to use)
- When to intervene in team dynamics vs let teams self-organize
- When to change estimation approaches
- When to escalate team dysfunction

**Required Research**: Execute queries focused on:
- Comparison searches (Areas 1, 2, 4)
- Anti-pattern searches (Areas 1-5)
- Real-world experience searches (Areas 1-6)

**Example Format** (when research is complete):
- When team consistently fails sprint commitments, diagnose as over-commitment or unclear stories, recommend sprint planning refinement and capacity-based planning, because sustainable pace requires realistic forecasting: [source URL] [Confidence: MEDIUM]

### 3. Anti-Patterns Catalog

**GAP**: This section should document common mistakes such as:
- **Cargo Cult Scrum**: Following ceremonies without understanding principles
- **Estimation Theater**: Elaborate estimation without actual value
- **Retrospective Fatigue**: Retros without actions or follow-through
- **Waterfall in Disguise**: Long sprints with mini-waterfall phases
- **Velocity Gaming**: Optimizing for metric instead of value delivery
- **Scaled Prematurely**: Scaling frameworks before mastering team-level agile
- **Metric Misuse**: Using DORA/SPACE metrics for performance reviews

**Required Research**: Execute anti-pattern queries in all research areas, especially:
- Area 1: Agile practice anti-patterns
- Area 2: Sprint and estimation anti-patterns
- Area 3: Coaching anti-patterns
- Area 4: Scaling anti-patterns
- Area 5: Metrics anti-patterns

**Example Format** (when research is complete):
- **Retrospective Theater**: Teams hold retrospectives but never implement actions, leading to cynicism and disengagement -> Destroys trust in the process and prevents genuine improvement -> Implement action tracking with accountability, limit actions to 1-3 per sprint, review action completion before planning new ones: [source URL]

### 4. Tool & Technology Map

**GAP**: This section should map tools across categories:

**Sprint/Kanban Boards**:
- Jira (proprietary, enterprise features, complex)
- Linear (modern, fast, developer-focused)
- Shortcut (mid-market, user-friendly)
- Azure DevOps (Microsoft ecosystem)
- GitHub Projects (integrated with repos)

**Selection Criteria**: [Needs research on when to choose each]

**Flow Metrics & Analytics**:
- [Tools require research - ActionableAgile, Nave, etc.]

**Retrospective Tools**:
- [Tools require research - Retrium, FunRetro, Metro Retro, etc.]

**OKR/Goal Tracking**:
- [Tools require research - Gtmhub, Ally.io, Lattice, etc.]

**AI-Augmented Agile Tools**:
- [Tools require research - 2025-2026 emerging tools]

**Required Research**: Execute queries:
- `"agile project management tools comparison 2026"`
- `"flow metrics tools 2025"`
- `"retrospective tools comparison"`
- `"OKR software tools comparison"`
- Tool-specific searches for current versions and features

### 5. Interaction Scripts

**GAP**: This section should provide response patterns for common coaching requests.

**Scenarios requiring scripts** (when research is complete):

**Trigger 1**: "Improve our sprint process"
- **Response pattern**: Assess current state (ceremonies, metrics, team satisfaction), identify bottlenecks (planning, execution, review), recommend specific improvements
- **Key questions**: What ceremonies do you currently have? What metrics do you track? Where do sprints typically struggle? What's your sprint length?

**Trigger 2**: "Coach our team on agile"
- **Response pattern**: Assess agile maturity level, identify knowledge gaps, provide targeted education, facilitate practice adoption
- **Key questions**: What's your current process? What agile framework are you using? What challenges are you facing? What's your team's experience level?

**Trigger 3**: "Scale agile across teams"
- **Response pattern**: Assess organizational readiness, evaluate scaling frameworks, design coordination mechanisms, plan incremental rollout
- **Key questions**: How many teams? What dependencies exist? What's your organizational structure? Are individual teams mature in agile?

**Trigger 4**: "Our retrospectives aren't working"
- **Response pattern**: Diagnose retro dysfunction (no actions, no follow-through, unsafe environment), recommend format changes, establish action tracking
- **Key questions**: What format do you use? Do you track actions? Are people candid? What happens to action items?

**Trigger 5**: "How should we estimate?"
- **Response pattern**: Assess team context, explain estimation approach trade-offs, recommend approach based on team needs
- **Key questions**: What's your current approach? What problems are you experiencing? How do you use estimates? What's your team size?

**Trigger 6**: "Measure our agile effectiveness"
- **Response pattern**: Recommend DORA/SPACE metrics, explain flow metrics, set up measurement infrastructure, establish baseline
- **Key questions**: What do you currently measure? What decisions need data? What's your deployment pipeline? What tools do you use?

**Trigger 7**: "Handle AI developers in our agile process"
- **Response pattern**: Adapt velocity tracking for AI-assisted development, adjust estimation approach, modify code review practices
- **Key questions**: Which AI tools are you using? How has productivity changed? How do you currently estimate?

**Required Research**: All areas inform interaction scripts, especially:
- Area 1: General agile practices
- Area 2: Sprint and iteration specifics
- Area 3: Coaching techniques
- Area 4: Scaling guidance
- Area 5: Metrics implementation
- Area 6: AI adaptation

---

## Identified Gaps

### Complete Research Campaign Gap

**All 6 Research Areas - All 28 Sub-Questions**

**Root Cause**: WebSearch and WebFetch tools unavailable in this execution environment.

**Failed Queries**: N/A - queries were planned but could not be executed due to tool unavailability.

**Planned Queries Summary**:
- **Area 1**: 20+ queries across agile practices, framework evolution, remote patterns, AI integration, and effectiveness measurement
- **Area 2**: 20+ queries across sprint planning, estimation approaches, retrospectives, scope management, and DoD
- **Area 3**: 20+ queries across coaching practices, team dysfunction, psychological safety, servant leadership, and transformation
- **Area 4**: 20+ queries across scaling frameworks, multi-team coordination, portfolio planning, dependency management, and transformation
- **Area 5**: 20+ queries across DORA/SPACE metrics, flow metrics, data-driven coaching, continuous improvement, and OKRs
- **Area 6**: 20+ queries across AI impact, AI-assisted planning, AI-first development, AI retrospectives, and velocity impact

**Total Planned Queries**: 100+ queries following the Deep Research Agent bias mitigation protocol (benefits, drawbacks, comparisons, real-world experience for each topic).

### Research Execution Requirements

To complete this research campaign, the following is required:

1. **Enable Web Research Tools**:
   - WebSearch: For broad discovery across all topics
   - WebFetch: For detailed extraction from authoritative sources

2. **Follow Deep Research Agent Protocol**:
   - **Phase 3 (Broad Sweep)**: Execute 1-2 searches per area (12-24 total)
   - **Phase 4 (Deep Dive)**: Execute targeted follow-ups (30-50 additional searches)
   - **Phase 5 (Cross-Reference)**: Identify patterns and connections
   - **Phase 6 (Synthesis)**: Populate all five synthesis categories

3. **CRAAP Evaluation**: Apply scoring rubric to all sources, prioritizing:
   - Currency: 2025-2026 sources (agile and AI are rapidly evolving)
   - Relevance: Direct answers to sub-questions
   - Authority: Official documentation, recognized experts, practitioner experience
   - Accuracy: Evidence-based, acknowledges trade-offs
   - Purpose: Educational intent, not marketing

4. **Confidence Rating**: Rate all findings as HIGH/MEDIUM/LOW based on:
   - HIGH: 3+ independent authoritative sources agree
   - MEDIUM: 2 sources agree or 1 highly authoritative source
   - LOW: Single source or emerging practice

5. **Source Attribution**: Every finding must include source URL

### Critical Agile Coach Knowledge Domains Requiring Research

The following knowledge domains are essential for an effective Agile Coach agent:

**Foundational Knowledge** (Areas 1-2):
- Core agile principles and values
- Scrum vs Kanban vs hybrid approaches
- Sprint ceremonies and best practices
- Estimation techniques and trade-offs
- Retrospective formats and facilitation

**Coaching Skills** (Area 3):
- Team dysfunction identification (Lencioni model)
- Psychological safety building
- Servant leadership principles
- Change management and transformation coaching

**Scaling Expertise** (Area 4):
- SAFe vs LeSS vs Nexus comparison
- Multi-team coordination patterns
- Portfolio-level agile planning
- Dependency management techniques

**Metrics and Improvement** (Area 5):
- DORA metrics (deployment frequency, lead time, MTTR, change fail rate)
- SPACE framework (Satisfaction, Performance, Activity, Communication, Efficiency)
- Flow metrics (cycle time, throughput, WIP)
- OKR integration with agile planning

**AI-Augmented Agile** (Area 6):
- Impact of AI coding assistants on velocity
- AI-assisted sprint planning patterns
- Adapting agile for AI-first teams
- AI-generated insights and coaching

---

## Cross-References

**GAP**: Cross-area analysis requires completed research in all areas.

**Planned Cross-Reference Analysis** (when research is complete):

1. **DORA Metrics (Area 5) → Sprint Practices (Area 2)**:
   - How do sprint practices impact DORA metrics?
   - Which sprint patterns lead to higher deployment frequency?

2. **Psychological Safety (Area 3) → Retrospectives (Area 2)**:
   - How does psychological safety enable effective retrospectives?
   - What retro formats build psychological safety?

3. **AI Tools (Area 6) → Velocity Planning (Area 2)**:
   - How do AI coding assistants change velocity calculations?
   - Should estimation approaches change with AI pair programming?

4. **Scaling Frameworks (Area 4) → Team Coaching (Area 3)**:
   - What coaching patterns are needed for scaled agile?
   - How does scaling impact team dynamics?

5. **Flow Metrics (Area 5) → Kanban Practices (Area 1)**:
   - How do Kanban practices optimize flow metrics?
   - Which metrics matter most for Kanban teams?

6. **Remote Patterns (Area 1) → All Other Areas**:
   - How do remote/distributed teams adapt sprint ceremonies?
   - How does remote work impact psychological safety?
   - How do remote teams coordinate in scaled agile?

**Required Research**: Complete all 6 areas, then perform convergence analysis to identify patterns across multiple areas.

---

## Research Quality Self-Check

### Checklist Status (All Items FAIL - Research Not Completed)

- ❌ Every sub-question has at least one finding or is documented as GAP
  - **Status**: All 28 sub-questions are documented GAPS
- ❌ Every finding has a source URL or specific citation
  - **Status**: Zero findings, zero sources
- ❌ Every finding has a confidence level (HIGH, MEDIUM, LOW)
  - **Status**: N/A - no findings
- ❌ No finding relies solely on a single vendor source without corroboration
  - **Status**: N/A - no findings
- ❌ All five synthesis categories have substantive content
  - **Status**: All five categories are GAPS
- ❌ Contradictions are documented with resolution or framing
  - **Status**: N/A - no findings to contradict
- ❌ Gaps are documented with all queries attempted
  - **Status**: Queries planned but not attempted (tools unavailable)
- ❌ Research areas are proportionally covered
  - **Status**: All areas equally uncovered (0%)
- ❌ Findings are specific and actionable
  - **Status**: N/A - no findings
- ❌ Passes Agent Builder Test: Could non-expert build agent from this output?
  - **Status**: FAIL - output contains framework only, no knowledge content

### Overall Assessment

**This research output is INCOMPLETE and NOT READY for agent building.**

The output documents:
- ✅ Complete research framework and query plans
- ✅ Proper gap documentation per protocol
- ✅ No fabricated findings (maintains research integrity)
- ❌ Zero completed research
- ❌ Zero source evaluations
- ❌ Zero actionable knowledge for agent builder

**Blocker**: Web research tools (WebSearch, WebFetch) unavailable.

**Next Steps**:
1. Enable web research tools in the execution environment
2. Re-run this research prompt with tools available
3. Execute the 100+ planned queries documented above
4. Apply CRAAP evaluation to all sources
5. Populate synthesis categories with attributed findings
6. Perform cross-reference analysis
7. Deliver complete research output (target: 1000-1500 lines with findings)

---

## Appendix: Research Framework for Tool-Enabled Execution

### Recommended Research Sequence (When Tools Available)

**Phase 3 - Broad Sweep (Estimated: 20-25 searches)**:

1. **Start with official documentation** (highest authority):
   - Scrum Guide (scrumguides.org)
   - Agile Manifesto (agilemanifesto.org)
   - DORA documentation (dora.dev)

2. **Target recognized authorities**:
   - Martin Fowler (martinfowler.com/agile.html)
   - Scrum.org resources
   - Atlassian Agile guides

3. **Execute 2-3 searches per research area** for initial coverage

**Phase 4 - Deep Dive (Estimated: 40-60 searches)**:

1. **Area 6 (AI-Augmented) priority**: Most rapidly evolving, requires current sources
2. **Area 5 (Metrics) priority**: Foundation for coaching effectiveness
3. **Areas 1-2**: Core knowledge needed by all coaches
4. **Areas 3-4**: Specialized coaching and scaling knowledge

**Phase 5 - Cross-Reference**:

1. Look for convergence across areas (same practice mentioned in multiple contexts)
2. Identify contradictions (different recommendations for different contexts)
3. Map dependencies (Area 6 findings may contradict Area 2 traditional practices)

**Phase 6 - Synthesis**:

1. Organize findings by synthesis category
2. Rate confidence levels
3. Document decision frameworks
4. Create interaction scripts

### Estimated Effort When Tools Available

- **Phase 3**: 2-3 hours (broad sweep across 6 areas)
- **Phase 4**: 4-6 hours (deep dive with targeted follow-ups)
- **Phase 5**: 1-2 hours (cross-reference analysis)
- **Phase 6**: 2-3 hours (synthesis and output writing)

**Total**: 9-14 hours of research time to produce a comprehensive, source-attributed research output ready for agent building.

---

## Notes for Agent Builder (Step 5)

When this research is completed, the agent builder should use this output to create an Agile Coach agent with:

**Core Capabilities**:
- Assess agile maturity levels
- Diagnose team dysfunctions
- Recommend process improvements
- Facilitate ceremony changes
- Coach on estimation approaches
- Implement metrics and measurement
- Guide scaling efforts
- Adapt practices for AI-augmented teams

**Agent Archetype**: Coach/Orchestrator (not Implementer)
- Focuses on team practices and improvement
- Guides rather than prescribes
- Asks diagnostic questions
- Provides contextual recommendations
- Measures and tracks improvement

**Integration Points** (from research prompt):
- Complement delivery-manager (delivery-manager handles project execution)
- Hand off to delivery-manager for timeline and milestone management
- Receive from team-progress-tracker for performance data
- Collaborate with ai-team-transformer on AI-augmented practices
- Never overlap with delivery-manager on project tracking

**Decision-Making Style**:
- Diagnostic first (understand current state)
- Contextual recommendations (no one-size-fits-all)
- Evidence-based when possible (use metrics)
- Iterative improvement (small changes, measure, adjust)

**Anti-Patterns to Avoid in Agent Design**:
- Don't be prescriptive ("you must do Scrum")
- Don't ignore context (team size, domain, maturity)
- Don't recommend scaling prematurely
- Don't focus on metrics without improvement actions
- Don't recommend AI tools without understanding current practices

---

## End of Research Output

**Status**: INCOMPLETE - Awaiting web research tool availability

**Recommendation**: Re-execute this research prompt in an environment with WebSearch and WebFetch tools enabled to produce a complete, source-attributed research synthesis suitable for agent building.

**Framework Quality**: This document demonstrates proper gap documentation per the Deep Research Agent protocol. It does not fabricate findings, properly documents all planned queries, and maintains research integrity by refusing to generate unsourced content.
